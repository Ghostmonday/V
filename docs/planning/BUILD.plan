# VibeZ Unified Build Plan

**Last Updated**: 2025-01-XX  
**Status**: Active Development  
**Purpose**: Single source of truth for all remaining implementation work

---

## Overview

This document consolidates all remaining work items from previous planning documents, validation reports, and identified gaps in the codebase. It serves as the authoritative roadmap for completing VibeZ's production readiness.

### Current State
- **Backend API**: Core Express server with WebSocket gateway operational
- **Database**: Supabase PostgreSQL with migrations and RLS policies
- **Authentication**: JWT-based auth with refresh tokens (partial implementation)
- **VIBES Features**: Core skeleton complete, needs AI integration
- **Security**: Basic middleware in place, needs hardening
- **Testing**: Minimal test coverage, needs comprehensive suite
- **Monitoring**: Prometheus metrics endpoint, needs full observability stack

---

## Phase 1: Security & Authentication Hardening

**Status**: Partially Complete  
**Priority**: Critical  
**Estimated Hours**: 120

### 1.1 Refresh Token Rotation & Security
**Files**: `src/services/refresh-token-service.ts`, `sql/migrations/2025-01-XX-refresh-tokens.sql`

**Tasks**:
- [ ] Implement token family tracking for reuse detection
  - Generate UUID family_id on token creation
  - Store family_id with token hash in database
- [ ] Add server-side invalidation on token reuse
  - Detect reuse via last_used_at timestamp
  - Invalidate entire token family on reuse detection
- [ ] Store SHA256 hashes instead of raw tokens
  - Validate hash format (64 char hex string)
  - Update token verification logic
- [ ] Add comprehensive audit logging for token events
  - Log rotation, reuse, and invalidation events
  - Include user_id, event_type, timestamp, IP address

**Acceptance Criteria**:
- Token reuse detected and entire family invalidated
- All tokens stored as hashes, never plaintext
- Audit log entries created for all token operations
- Token rotation works without breaking existing sessions

### 1.2 Enhanced Password Security
**Files**: `src/services/user-authentication-service.ts`, `frontend/iOS/Services/FirebaseAuthRepository.swift`

**Tasks**:
- [ ] Migrate remaining plaintext passwords to bcrypt/argon2
  - Identify plaintext passwords in database
  - Hash and update in batches
  - Verify migration success
- [ ] Enforce password strength requirements
  - Minimum 8 characters, maximum 500
  - Complexity rules (uppercase, lowercase, numbers, symbols)
  - Validate on registration and password change
- [ ] Implement argon2 as alternative to bcrypt
  - Add argon2 library dependency
  - Support both hash formats during transition
  - Update verification logic

**Acceptance Criteria**:
- Zero plaintext passwords in database
- Password strength validation enforced
- Both bcrypt and argon2 hashes supported

### 1.3 Role-Based Access Control (RBAC)
**Files**: `sql/11_indexing_and_rls.sql`, `src/middleware/admin-auth.ts`

**Tasks**:
- [ ] Create role hierarchy: user → moderator → admin → owner
  - Define role enum/types
  - Implement role comparison logic
- [ ] Add middleware for role checking
  - Extract user ID from request
  - Check role against required permission
  - Return 403 on insufficient permissions
- [ ] Implement permission matrix
  - Define permissions per role
  - Support permission inheritance (admin has mod permissions)
  - Add room-level role checking

**Acceptance Criteria**:
- Role hierarchy enforced consistently
- Middleware correctly checks permissions
- Room-level roles work alongside global roles

### 1.4 Brute-Force Protection Enhancement
**Files**: `src/middleware/brute-force-protection.ts`, `src/middleware/rate-limiter.ts`

**Tasks**:
- [ ] Implement Redis-based distributed rate limiting
  - Store attempt counts in Redis (5/min per IP)
  - Support multiple server instances
- [ ] Add exponential backoff for lockouts
  - Track lockout duration per user/IP
  - Increase lockout time on repeated violations
- [ ] Integrate CAPTCHA after 3 failures
  - Add CAPTCHA service integration (reCAPTCHA/hCaptcha)
  - Require CAPTCHA token on login after threshold
- [ ] Add account lockout after 5 failures
  - Lock account for 15 minutes initially
  - Escalate lockout duration on repeated violations

**Acceptance Criteria**:
- Rate limiting works across multiple server instances
- CAPTCHA required after 3 failed attempts
- Account lockout after 5 failures
- No false positives blocking legitimate users

### 1.5 HTTPS/TLS Enforcement
**Files**: `src/server/index.ts`

**Tasks**:
- [ ] Verify HSTS headers configured correctly
  - Validate max-age value (31536000)
  - Ensure includeSubDomains and preload flags set
- [ ] Enforce HTTPS redirects in production
  - Redirect HTTP to HTTPS (301/308)
  - Validate certificate chain
- [ ] Add security.txt file
  - Create `/.well-known/security.txt`
  - Include security contact information

**Acceptance Criteria**:
- HSTS headers present in all responses
- HTTP requests redirected to HTTPS in production
- Security.txt accessible and properly formatted

---

## Phase 2: WebSocket & Messaging Optimization

**Status**: Core Complete, Needs Optimization  
**Priority**: High  
**Estimated Hours**: 100

### 2.1 Message Rate Limiting
**Files**: `src/middleware/ws-message-rate-limiter.ts`, `src/ws/handlers/messaging.ts`

**Tasks**:
- [ ] Enforce 15 messages/30 seconds per user
  - Check rate limit before message send
  - Increment message count on send
  - Return 429 response when limit exceeded
- [ ] Add configurable limits by user tier
  - Define tier-based limit lookup
  - Enterprise users get higher limits
- [ ] Implement sliding window algorithm
  - Track messages in time window
  - Remove old entries after 30 seconds

**Acceptance Criteria**:
- Rate limits enforced per user
- Tier-based limits work correctly
- Sliding window resets properly

### 2.2 Connection Health & Scaling
**Files**: `src/ws/gateway.ts`

**Tasks**:
- [ ] Add configurable idle timeout (5 minutes)
  - Close connections after idle period
  - Send ping/pong to detect dead connections
- [ ] Implement reconnection backoff
  - Exponential backoff delay (max 30 seconds)
  - Track reconnection attempts
- [ ] Add connection quality metrics
  - Measure ping/pong latency
  - Calculate connection quality score
  - Log quality metrics to telemetry

**Acceptance Criteria**:
- Idle connections closed after timeout
- Reconnection backoff prevents server overload
- Connection quality tracked and logged

### 2.3 Delivery Acknowledgements
**Files**: `src/ws/handlers/messaging.ts`

**Tasks**:
- [ ] Add ack system with message IDs
  - Generate UUID for each message
  - Track pending acknowledgements
- [ ] Track delivery status (pending/delivered/failed)
  - Store status in database
  - Update status on ack receipt
- [ ] Add retry logic for failed deliveries
  - Retry after 5 second timeout
  - Max 3 retry attempts
  - Mark as failed after max retries

**Acceptance Criteria**:
- Message IDs generated and tracked
- Delivery status updated on ack receipt
- Failed messages retried automatically

### 2.4 WebSocket Scaling
**Files**: `src/ws/gateway.ts`, `src/config/redis-pubsub.ts`

**Tasks**:
- [ ] Add connection limits per room (1000 max)
  - Check room connection count on join
  - Graceful degradation when limit reached
- [ ] Implement Node.js clustering support
  - Use cluster module for multi-process
  - Share WebSocket connections across workers
- [ ] Add Redis for cross-process broadcasting
  - Publish messages to Redis pub/sub
  - Subscribe to Redis in all workers
  - Broadcast to local connections

**Acceptance Criteria**:
- Room connection limits enforced
- Multiple server instances can handle same room
- Messages broadcast across all instances

---

## Phase 3: Database & Performance Optimization

**Status**: Basic Indexes, Needs Optimization  
**Priority**: High  
**Estimated Hours**: 80

### 3.1 Performance Indexes
**Files**: `MISSING_INDEXES_REPORT.sql`, `sql/migrations/`

**Tasks**:
- [ ] Apply missing indexes from report
  - messages(sender_id, room_id, created_at)
  - conversation_participants(user_id, conversation_id)
  - Other high-impact indexes
- [ ] Run Supabase Index Advisor
  - Analyze query patterns
  - Generate index recommendations
- [ ] Monitor index usage
  - Track index usage in metrics
  - Identify unused indexes for removal

**Acceptance Criteria**:
- All critical indexes created
- Query execution time < 100ms for common queries
- Index usage monitored and optimized

### 3.2 Query Pagination
**Files**: `src/shared/supabase-helpers.ts`, `src/services/query-optimization-service.ts`

**Tasks**:
- [ ] Add cursor-based pagination
  - Support timestamp and UUID cursors
  - Calculate next/prev cursor correctly
- [ ] Implement limit/offset fallback
  - Use when cursor unavailable
  - Enforce limit (1-100) validation
- [ ] Add pagination metadata
  - Return total count (if available)
  - Include has_more flag

**Acceptance Criteria**:
- Cursor-based pagination works for all list endpoints
- Limit enforced (max 100 per page)
- Pagination metadata included in responses

### 3.3 Message Archival
**Files**: `src/services/message-archival-service.ts`

**Tasks**:
- [ ] Move messages > 90 days to cold storage
  - Identify eligible messages
  - Move to archive table
  - Verify data integrity
- [ ] Implement encrypted archives
  - Encrypt before archival
  - Decrypt on retrieval
- [ ] Add retrieval API
  - Endpoint to retrieve archived messages
  - Verify archive integrity (checksum)

**Acceptance Criteria**:
- Messages archived after 90 days
- Archives encrypted at rest
- Archived messages retrievable via API

### 3.4 Redis Caching
**Files**: `src/services/cache-service.ts`

**Tasks**:
- [ ] Add Redis caching for hot data
  - Cache frequently accessed data
  - Set appropriate TTLs
- [ ] Implement cache invalidation
  - Invalidate on data updates
  - Support cache warming
- [ ] Add cache metrics
  - Track hit/miss rates
  - Monitor cache size

**Acceptance Criteria**:
- Hot data cached in Redis
- Cache invalidation works correctly
- Cache metrics tracked

---

## Phase 4: AI & VIBES Features Integration

**Status**: Skeleton Complete, Needs AI Integration  
**Priority**: Medium  
**Estimated Hours**: 60

### 4.1 Sentiment Analysis Integration
**Files**: `src/services/vibes/sentiment-service.ts`, `src/services/sentiment-analysis-service.ts`

**Tasks**:
- [ ] Replace placeholder with real NLP library
  - Integrate TextBlob or sentiment npm package
  - Return polarity (-1 to 1) and confidence (0 to 1)
- [ ] Add error handling and fallback
  - Catch NLP errors
  - Return neutral sentiment on failure
  - Log errors for monitoring
- [ ] Implement result caching
  - Cache in Redis with 1-hour TTL
  - Cache key based on conversation hash
  - Add cache warming for active conversations

**Acceptance Criteria**:
- Sentiment analysis returns accurate polarity scores
- Errors handled gracefully with fallback
- Results cached to reduce API calls

### 4.2 Card Generation AI Integration
**Files**: `src/services/vibes/card-generator.ts`

**Tasks**:
- [ ] Integrate DALL-E for artwork generation
  - Call DALL-E API with conversation context
  - Generate image based on rarity tier
  - Store image URL in database
- [ ] Implement title generation
  - Use OpenAI GPT for title generation
  - Generate titles based on conversation sentiment
- [ ] Implement caption generation
  - Generate captions summarizing conversation
  - Include key moments and participants

**Acceptance Criteria**:
- Cards generated with AI artwork
- Titles and captions generated automatically
- Images stored and accessible

### 4.3 Batch Processing & Queues
**Files**: `src/services/message-queue.ts`

**Tasks**:
- [ ] Implement batch LLM calls
  - Group 10-50 requests per batch
  - Reduce API call overhead
- [ ] Add async queue (BullMQ)
  - Queue card generation jobs
  - Process jobs asynchronously
- [ ] Add dynamic rate limiting
  - Respect API provider limits
  - Adjust rate based on provider
- [ ] Implement error retries
  - Retry failed jobs with backoff
  - Monitor queue backlogs

**Acceptance Criteria**:
- LLM calls batched efficiently
- Queue processes jobs asynchronously
- Rate limiting prevents API throttling
- Failed jobs retried automatically

---

## Phase 5: Moderation & Safety

**Status**: Basic Implementation, Needs Enhancement  
**Priority**: High  
**Estimated Hours**: 50

### 5.1 Perspective API Integration
**Files**: `src/services/perspective-api-service.ts`, `src/services/moderation.service.ts`

**Tasks**:
- [ ] Add Perspective API key configuration
  - Store key securely (vault/env)
  - Validate key format
- [ ] Implement toxicity scoring
  - Call Perspective API for toxicity scores
  - Parse attribute scores (toxicity, severe_toxicity, etc.)
- [ ] Add error handling and fallback
  - Fallback to DeepSeek on Perspective failure
  - Log API errors

**Acceptance Criteria**:
- Perspective API integrated
- Toxicity scores returned (0-1 range)
- Fallback to DeepSeek on failure

### 5.2 Configurable Thresholds
**Files**: `src/services/moderation.service.ts`

**Tasks**:
- [ ] Implement warning threshold (0.6)
  - Send warning when score > 0.6
  - Log warning event
- [ ] Implement block threshold (0.8)
  - Block message when score > 0.8
  - Notify user of block
- [ ] Add per-room custom thresholds
  - Allow room-specific threshold override
  - Require admin permission for updates

**Acceptance Criteria**:
- Warning sent at 0.6 threshold
- Message blocked at 0.8 threshold
- Per-room thresholds configurable

### 5.3 Flagging System Enhancement
**Files**: `src/services/message-flagging-service.ts`, `sql/migrations/2025-01-XX-flagged-messages.sql`

**Tasks**:
- [ ] Auto-flagging on toxicity
  - Flag message when score > threshold
  - Store flag reason ('toxicity')
- [ ] Manual flagging UI integration
  - Allow users to flag messages
  - Select flag reason from enum
- [ ] Status tracking
  - Track flag status (pending/reviewed/resolved)
  - Validate status transitions

**Acceptance Criteria**:
- Messages auto-flagged on toxicity
- Users can manually flag messages
- Flag status tracked and updated

---

## Phase 6: Observability & Operations

**Status**: Basic Metrics, Needs Full Stack  
**Priority**: Medium  
**Estimated Hours**: 70

### 6.1 Structured Logging
**Files**: `src/middleware/structured-logging.ts`

**Tasks**:
- [ ] Add request IDs and correlation IDs
  - Generate UUID on each request
  - Propagate across services
- [ ] Implement JSON log format
  - Structured log entries (timestamp, level, message, requestId)
  - Valid JSON output
- [ ] Add log aggregation
  - Send logs to aggregation service (ELK/OpenTelemetry)
  - Enable search by request ID

**Acceptance Criteria**:
- Request IDs generated and propagated
- Logs in JSON format
- Logs searchable by request ID

### 6.2 Metrics Collection Enhancement
**Files**: `src/services/monitoring-service.ts`, `src/services/telemetry-service.ts`

**Tasks**:
- [ ] Add custom business metrics
  - Rate limit metrics
  - Sentiment metrics
  - Moderation metrics
  - Card generation metrics
- [ ] Track slow queries
  - Log queries > 100ms
  - Capture query details
- [ ] Monitor connection pool
  - Track active/idle connections
  - Alert on pool exhaustion

**Acceptance Criteria**:
- Custom metrics tracked in Prometheus
- Slow queries logged
- Connection pool monitored

### 6.3 Error Alerting
**Files**: `src/middleware/error-alerting.ts`

**Tasks**:
- [ ] Slack webhook integration
  - Send alerts on error threshold exceeded
  - Include error context and stack trace
- [ ] Email alerts via SendGrid
  - Configure SendGrid API key
  - Send to configured recipients
- [ ] PagerDuty for critical issues
  - Integrate PagerDuty API
  - Trigger incidents on critical errors

**Acceptance Criteria**:
- Alerts sent to Slack on errors
- Email alerts configured
- Critical errors trigger PagerDuty incidents

### 6.4 Telemetry Optimization
**Files**: `src/services/telemetry-service.ts`

**Tasks**:
- [ ] Implement event sampling (10%)
  - Sample 10% of events
  - Preserve all critical events
- [ ] Add compression (gzip) before storage
  - Compress telemetry data
  - Reduce storage costs
- [ ] Integrate OpenTelemetry/ELK stack
  - Send telemetry to external service
  - Aggregate metrics

**Acceptance Criteria**:
- Event sampling reduces volume by 70%+
- Telemetry compressed before storage
- External telemetry service integrated

---

## Phase 7: Testing & Quality Assurance

**Status**: Minimal Coverage, Needs Comprehensive Suite  
**Priority**: High  
**Estimated Hours**: 100

### 7.1 Unit Tests
**Files**: `src/tests/`, `src/services/__tests__/`

**Tasks**:
- [ ] Auth service tests
  - Test token generation and verification
  - Test refresh token rotation
  - Test password hashing
- [ ] Rate limiting tests
  - Test rate limit enforcement
  - Test tier-based limits
- [ ] Sentiment analysis tests
  - Test sentiment calculation
  - Test error handling
- [ ] Moderation service tests
  - Test toxicity scoring
  - Test threshold enforcement

**Acceptance Criteria**:
- Test coverage > 80% for core services
- All unit tests pass
- Tests run in CI/CD

### 7.2 Integration Tests
**Files**: `src/tests/`

**Tasks**:
- [ ] WebSocket flow tests
  - Test connection establishment
  - Test message sending/receiving
  - Test delivery acknowledgements
- [ ] API endpoint tests
  - Test all major endpoints
  - Test authentication flows
  - Test error handling

**Acceptance Criteria**:
- WebSocket flows tested end-to-end
- All API endpoints tested
- Integration tests pass

### 7.3 Load Testing
**Files**: `scripts/load-test/`

**Tasks**:
- [ ] Set up load testing infrastructure
  - Configure k6 or Artillery
  - Create test scenarios
- [ ] Test 10k concurrent users
  - Verify system handles load
  - Measure response times
- [ ] Test 10k messages/sec
  - Verify messaging throughput
  - Check for bottlenecks

**Acceptance Criteria**:
- System handles 10k concurrent users
- Messaging throughput > 10k messages/sec
- Response times < 100ms under load

---

## Phase 8: Privacy & Compliance

**Status**: Basic GDPR Endpoints, Needs Full Implementation  
**Priority**: Medium  
**Estimated Hours**: 40

### 8.1 GDPR/CCPA Compliance
**Files**: `src/routes/user-data-routes.ts`, `src/services/`

**Tasks**:
- [ ] Complete data export endpoint
  - Export all user data (JSON format)
  - Include all related data (messages, cards, etc.)
- [ ] Complete data deletion endpoint
  - Soft delete with retention period
  - Anonymize data after retention
- [ ] Add consent management
  - Store consent records with timestamp
  - Support consent withdrawal

**Acceptance Criteria**:
- Users can export all their data
- Users can delete their data
- Consent tracked and manageable

### 8.2 Data Retention Policies
**Files**: `src/jobs/data-retention-cron.ts`

**Tasks**:
- [ ] Implement retention policies
  - Configure retention periods per data type
  - Auto-delete after retention period
- [ ] Add anonymization process
  - Anonymize PII before deletion
  - Preserve aggregated analytics

**Acceptance Criteria**:
- Data deleted after retention period
- PII anonymized before deletion
- Retention policies configurable

### 8.3 Column Encryption
**Files**: `src/services/encryption-service.ts`

**Tasks**:
- [ ] Encrypt PII fields at rest
  - Encrypt emails, tokens, IP addresses
  - Use Supabase Vault for key management
- [ ] Implement transparent decryption
  - Decrypt on read (transparent to application)
  - Handle decryption errors gracefully

**Acceptance Criteria**:
- PII fields encrypted at rest
- Decryption transparent to application
- Key rotation supported

---

## Phase 9: Performance & Scalability

**Status**: Basic Implementation, Needs Optimization  
**Priority**: Medium  
**Estimated Hours**: 80

### 9.1 Database Sharding
**Files**: `src/services/`, `sql/migrations/`

**Tasks**:
- [ ] Design sharding strategy
  - Determine shard key (user_id or room_id)
  - Plan data distribution
- [ ] Implement sharding logic
  - Route queries to correct shard
  - Handle cross-shard queries
- [ ] Add shard management
  - Monitor shard health
  - Rebalance shards as needed

**Acceptance Criteria**:
- Messages distributed across shards
- Queries routed correctly
- Shard health monitored

### 9.2 Pub/Sub Integration
**Files**: `src/config/redis-pubsub.ts`

**Tasks**:
- [ ] Integrate RabbitMQ or Redis Streams
  - Set up message broker
  - Configure topics/channels
- [ ] Implement message routing
  - Route messages to correct handlers
  - Support message archival

**Acceptance Criteria**:
- Pub/sub system operational
- Messages routed correctly
- Archival via pub/sub works

### 9.3 Dynamic Partitioning
**Files**: `src/jobs/partition-management-cron.ts`

**Tasks**:
- [ ] Optimize partitioning cron
  - Dynamic thresholds based on load
  - Monitor partition sizes
- [ ] Add partition monitoring
  - Track partition health
  - Alert on partition issues

**Acceptance Criteria**:
- Partitions created dynamically
- Thresholds adjust based on load
- Partition health monitored

---

## Phase 10: Documentation & Developer Experience

**Status**: Needs Comprehensive Documentation  
**Priority**: Low  
**Estimated Hours**: 30

### 10.1 API Documentation
**Files**: `specs/api/openapi.yaml`

**Tasks**:
- [ ] Complete OpenAPI specification
  - Document all endpoints
  - Include request/response examples
  - Add authentication details
- [ ] Generate API docs
  - Use Swagger UI or similar
  - Host docs at `/api/docs`

**Acceptance Criteria**:
- All endpoints documented
- API docs accessible and accurate
- Examples provided for all endpoints

### 10.2 Developer Documentation
**Files**: `README.md`, `docs/`

**Tasks**:
- [ ] Write setup guide
  - Environment setup
  - Database migrations
  - Local development
- [ ] Document architecture
  - System architecture diagram
  - Component descriptions
  - Data flow diagrams
- [ ] Add troubleshooting guide
  - Common issues and solutions
  - Debugging tips

**Acceptance Criteria**:
- Setup guide complete and accurate
- Architecture documented
- Troubleshooting guide helpful

---

## Success Criteria Summary

### Performance Targets
- Handle 10k messages/sec without bottlenecks
- Support 50k concurrent WebSocket users with <100ms latency
- Achieve 50% query speedup on 1M row queries
- Process 1k vibe generations with <1% failure rate
- Stable streaming for 500 users in voice/video rooms

### Security Targets
- Zero plaintext passwords or tokens in database
- All PII encrypted at rest
- Rate limiting prevents brute-force attacks
- Token rotation prevents token reuse attacks
- Comprehensive audit logging for security events

### Quality Targets
- Test coverage > 80% for core services
- All integration tests passing
- Load tests validate scalability
- Zero critical security vulnerabilities
- GDPR/CCPA compliance verified

---

## Implementation Notes

### Validation Strategy
Every implementation step MUST include validation points:
- Validate input format before processing
- Validate data structure before database operations
- Validate output format before returning responses
- Log validation failures for monitoring

### Testing Strategy
- Write tests before or alongside implementation
- Test happy paths and error cases
- Include integration tests for critical flows
- Run load tests before production deployment

### Deployment Strategy
- Deploy incrementally (feature flags)
- Monitor metrics after each deployment
- Rollback plan for each deployment
- Gradual rollout for high-risk changes

---

**End of Build Plan**
